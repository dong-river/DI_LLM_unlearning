verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 16
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.5
num_epochs_su: 100
lr_su: 1e-06
su_strength: 10.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 1.2816
--------------------------------------------------
wikitext_perplexity: 119.81554604049623
wikitext_rep_2: 0.047948337705930474
wikitext_rep_3: 0.006556810917818621
wikitext_rep_4: 0.0011673780040223007
wikitext_div_2: 0.937178619625224
wikitext_div_3: 0.9642687623946224
wikitext_mauve: 0.21571488513912074
wikitext_coherence: 0.48606579635792424
wikitext_similarity_gen: 0.3049701768063579
news_perplexity: 101.26648832053574
news_rep_2: 0.036489288435938405
news_rep_3: 0.004267320068261996
news_rep_4: 0.0005954325732497873
news_div_2: 0.9481346474380576
news_div_3: 0.9668928245162705
news_mauve: 0.13593442268875813
news_coherence: 0.48773479081719995
news_similarity_gen: 0.3823461392495514
el_3: 0.012905649854689751
el_5: 0.0016853461774529776
el_10: 6.897556565952781e-05
similarity_ul: 0.3363464265276484
ma: 0.5356
piqa_: 0.6508620689655172
ai2_arc_ARC-Easy: 0.39699074074074076
ai2_arc_ARC-Challenge: 0.39699074074074076
super_glue_copa: 0.703125
winogrande_winogrande_s: 0.5271792763157894
validation_data/pubmed_qa.csv_: 0.534375
hellaswag_: 0.3103258206761392

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 16
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.25
num_epochs_su: 100
lr_su: 1e-07
su_strength: 10.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 3.4181333333333335
--------------------------------------------------
wikitext_perplexity: 189.1284962074191
wikitext_rep_2: 0.061190567639142414
wikitext_rep_3: 0.011888769113048375
wikitext_rep_4: 0.003542138062063813
wikitext_div_2: 0.9197095146444642
wikitext_div_3: 0.951393759211327
wikitext_mauve: 0.07840937219675603
wikitext_coherence: 0.5145352888885076
wikitext_similarity_gen: 0.33195893427326695
news_perplexity: 69.46032505798107
news_rep_2: 0.05012115375412849
news_rep_3: 0.00996561251344661
news_rep_4: 0.0030324064919398657
news_div_2: 0.9354535558777056
news_div_3: 0.962981073554777
news_mauve: 0.1179446719638499
news_coherence: 0.5224333379373133
news_similarity_gen: 0.42533616988909934
el_3: 0.025779197110002105
el_5: 0.006199580591957821
el_10: 0.0009459473441831855
similarity_ul: 0.346168325335676
ma: 0.6579
piqa_: 0.6754156403940887
ai2_arc_ARC-Easy: 0.42939814814814814
ai2_arc_ARC-Challenge: 0.42939814814814814
super_glue_copa: 0.7109375
winogrande_winogrande_s: 0.5383634868421052
validation_data/pubmed_qa.csv_: 0.547265625
hellaswag_: 0.33154703576678096

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 16
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.25
num_epochs_su: 100
lr_su: 1e-07
su_strength: 3.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 4.273066666666667
--------------------------------------------------
wikitext_perplexity: 65.108835883218
wikitext_rep_2: 0.0890667230286609
wikitext_rep_3: 0.023354192545903107
wikitext_rep_4: 0.008234944254066607
wikitext_div_2: 0.8989313259933837
wikitext_div_3: 0.9516224489169982
wikitext_mauve: 0.23302651432448734
wikitext_coherence: 0.5363738132988943
wikitext_similarity_gen: 0.3443584565909923
news_perplexity: 31.93516230395535
news_rep_2: 0.06368537055413467
news_rep_3: 0.014864121072941947
news_rep_4: 0.005232205698106983
news_div_2: 0.9267463035528036
news_div_3: 0.9662829811311555
news_mauve: 0.32303336502187724
news_coherence: 0.5309023914109188
news_similarity_gen: 0.43970844814965715
el_3: 0.10565512082138497
el_5: 0.07183697089761153
el_10: 0.04141099892738356
similarity_ul: 0.4653223009084351
ma: 0.7448166666666667
piqa_: 0.6723368226600985
ai2_arc_ARC-Easy: 0.4318672839506173
ai2_arc_ARC-Challenge: 0.4318672839506173
super_glue_copa: 0.7109375
winogrande_winogrande_s: 0.5245476973684211
validation_data/pubmed_qa.csv_: 0.555078125
hellaswag_: 0.3290589784419402

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 16
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.5
num_epochs_su: 100
lr_su: 1e-06
su_strength: 3.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 4.273066666666667
--------------------------------------------------
wikitext_perplexity: 54.15815065923783
wikitext_rep_2: 0.0680901358211526
wikitext_rep_3: 0.014893203115009138
wikitext_rep_4: 0.004728717313355555
wikitext_div_2: 0.9209024162470896
wikitext_div_3: 0.9635507834039847
wikitext_mauve: 0.5270404673743423
wikitext_coherence: 0.5553505393761763
wikitext_similarity_gen: 0.3495659301433726
news_perplexity: 47.67214658505116
news_rep_2: 0.04762962291055267
news_rep_3: 0.008660549553218964
news_rep_4: 0.002155630363543883
news_div_2: 0.9409526153613113
news_div_3: 0.9686536184881238
news_mauve: 0.4372079376652658
news_coherence: 0.5240496753221489
news_similarity_gen: 0.42130948596752704
el_3: 0.10981407274170911
el_5: 0.07587426094552652
el_10: 0.04367425073619215
similarity_ul: 0.46932800715109335
ma: 0.74405
piqa_: 0.6460129310344828
ai2_arc_ARC-Easy: 0.40154320987654324
ai2_arc_ARC-Challenge: 0.40154320987654324
super_glue_copa: 0.6875
winogrande_winogrande_s: 0.5277138157894737
validation_data/pubmed_qa.csv_: 0.558984375
hellaswag_: 0.3101267760901519

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 16
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.05
num_epochs_su: 100
lr_su: 1e-07
su_strength: 3.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 2.3498666666666668
--------------------------------------------------
wikitext_perplexity: 38.73904070988888
wikitext_rep_2: 0.09567127016025716
wikitext_rep_3: 0.03378169145031836
wikitext_rep_4: 0.017365619224270094
wikitext_div_2: 0.893815912482353
wikitext_div_3: 0.9454919114389377
wikitext_mauve: 0.5117916552484403
wikitext_coherence: 0.5710845143163817
wikitext_similarity_gen: 0.38293387573866766
news_perplexity: 19.480905115236894
news_rep_2: 0.0663919253468035
news_rep_3: 0.02046595752814102
news_rep_4: 0.010014939301908273
news_div_2: 0.9249111736709366
news_div_3: 0.9624649108887058
news_mauve: 0.6220482323061678
news_coherence: 0.5615346840178349
news_similarity_gen: 0.4834946164410502
el_3: 0.09717501447935788
el_5: 0.06275398332084389
el_10: 0.03311557813658848
similarity_ul: 0.45939190459884705
ma: 0.7526
piqa_: 0.686884236453202
ai2_arc_ARC-Easy: 0.4423611111111111
ai2_arc_ARC-Challenge: 0.4423611111111111
super_glue_copa: 0.6640625
winogrande_winogrande_s: 0.5508634868421052
validation_data/pubmed_qa.csv_: 0.547265625
hellaswag_: 0.3476926139147477

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 16
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.1
num_epochs_su: 100
lr_su: 1e-07
su_strength: 10.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 2.5632
--------------------------------------------------
wikitext_perplexity: 102.892979416272
wikitext_rep_2: 0.0699499081047396
wikitext_rep_3: 0.018643217723591045
wikitext_rep_4: 0.00700407322732812
wikitext_div_2: 0.9139276229470059
wikitext_div_3: 0.9519096765593059
wikitext_mauve: 0.17592610433398362
wikitext_coherence: 0.5541257774515762
wikitext_similarity_gen: 0.36642644334750407
news_perplexity: 42.08001640017302
news_rep_2: 0.0546113823799557
news_rep_3: 0.013298937614957585
news_rep_4: 0.004905088849069723
news_div_2: 0.9331908340083915
news_div_3: 0.9633872977177912
news_mauve: 0.29714269727689535
news_coherence: 0.5463537694923432
news_similarity_gen: 0.46024923064396717
el_3: 0.0339506786199088
el_5: 0.010983986147225209
el_10: 0.0026022321113548814
similarity_ul: 0.3538298679682426
ma: 0.67035
piqa_: 0.6852678571428572
ai2_arc_ARC-Easy: 0.44112654320987654
ai2_arc_ARC-Challenge: 0.44112654320987654
super_glue_copa: 0.7265625
winogrande_winogrande_s: 0.5435855263157895
validation_data/pubmed_qa.csv_: 0.54921875
hellaswag_: 0.3419203209211171

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 16
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.05
num_epochs_su: 100
lr_su: 1e-07
su_strength: 10.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 2.3498666666666668
--------------------------------------------------
wikitext_perplexity: 106.41334531103372
wikitext_rep_2: 0.06860970085726116
wikitext_rep_3: 0.018762601894815847
wikitext_rep_4: 0.0071054466211947645
wikitext_div_2: 0.9134908551946795
wikitext_div_3: 0.9494584024464524
wikitext_mauve: 0.23138594325964074
wikitext_coherence: 0.5587619987305913
wikitext_similarity_gen: 0.37182782166210965
news_perplexity: 35.317109322688054
news_rep_2: 0.05607642904442494
news_rep_3: 0.015171399035978434
news_rep_4: 0.00640660635057472
news_div_2: 0.9325478237939192
news_div_3: 0.9624357087902774
news_mauve: 0.40836054519421516
news_coherence: 0.5534385893924303
news_similarity_gen: 0.4705789597898414
el_3: 0.03769031703956636
el_5: 0.013505803370133278
el_10: 0.003427524142541741
similarity_ul: 0.3606838662597739
ma: 0.6796833333333333
piqa_: 0.6831126847290641
ai2_arc_ARC-Easy: 0.44575617283950614
ai2_arc_ARC-Challenge: 0.44575617283950614
super_glue_copa: 0.7265625
winogrande_winogrande_s: 0.5428042763157894
validation_data/pubmed_qa.csv_: 0.547265625
hellaswag_: 0.34550312346888784

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 16
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.1
num_epochs_su: 100
lr_su: 1e-07
su_strength: 3.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 2.776533333333333
--------------------------------------------------
wikitext_perplexity: 52.81298113403389
wikitext_rep_2: 0.09119926699423862
wikitext_rep_3: 0.028371351856844397
wikitext_rep_4: 0.01213639787017533
wikitext_div_2: 0.8970223784104744
wikitext_div_3: 0.9483200789149093
wikitext_mauve: 0.30710702235770865
wikitext_coherence: 0.5674033745319361
wikitext_similarity_gen: 0.3749847457004498
news_perplexity: 23.02531465872844
news_rep_2: 0.06431440700927066
news_rep_3: 0.018221254176306673
news_rep_4: 0.00800725512006551
news_div_2: 0.9265480345013197
news_div_3: 0.9638289772113438
news_mauve: 0.5460369569503419
news_coherence: 0.5559300882407868
news_similarity_gen: 0.4729390008636171
el_3: 0.10060536231181995
el_5: 0.06626721284684832
el_10: 0.036482677993239614
similarity_ul: 0.46076199493691483
ma: 0.7474
piqa_: 0.6831126847290641
ai2_arc_ARC-Easy: 0.4446759259259259
ai2_arc_ARC-Challenge: 0.4446759259259259
super_glue_copa: 0.7265625
winogrande_winogrande_s: 0.5477384868421052
validation_data/pubmed_qa.csv_: 0.551171875
hellaswag_: 0.34172127633512983

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 32
num_epochs: 50
lr: 0.0001
peft: lora
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 2
lr_sc: 
warmup_steps: 100
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 1e-05
su_strength: 10.0
focus: True
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: True
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 23.243047584075434
wikitext_rep_2: 0.15315487293029173
wikitext_rep_3: 0.07570323191534938
wikitext_rep_4: 0.048338703625972305
wikitext_div_2: 0.8379099905458646
wikitext_div_3: 0.9052659892157546
wikitext_mauve: 0.43579094330545376
wikitext_coherence: 0.5896877542493334
wikitext_similarity_gen: 0.38789617013387206
news_perplexity: 14.778373182772588
news_rep_2: 0.11231457506123557
news_rep_3: 0.05219881543952808
news_rep_4: 0.03345995849857362
news_div_2: 0.8800051508565296
news_div_3: 0.9315678696856955
news_mauve: 0.5931438581992406
news_coherence: 0.5828150411051108
news_similarity_gen: 0.4852088998608473
el_3: 0.04853126917342356
el_5: 0.02585033774436365
el_10: 0.011891725456154524
similarity_ul: 0.40477536585249846
ma: 0.5945351084389092
piqa_: 0.6910406403940887
ai2_arc_ARC-Easy: 0.44004629629629627
ai2_arc_ARC-Challenge: 0.44004629629629627
super_glue_copa: 0.65625
winogrande_winogrande_s: 0.5414884868421053
validation_data/pubmed_qa.csv_: 0.5640625
hellaswag_: 0.3418207986281235

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 32
num_epochs: 50
lr: 0.0001
peft: lora
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 2
lr_sc: 
warmup_steps: 100
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 1e-06
su_strength: 3.0
focus: True
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: True
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 33.56164383561644
--------------------------------------------------
wikitext_perplexity: 20.620124950907844
wikitext_rep_2: 0.10505483848685335
wikitext_rep_3: 0.04063876670407609
wikitext_rep_4: 0.022413645545539682
wikitext_div_2: 0.8858596418882362
wikitext_div_3: 0.9414848681562803
wikitext_mauve: 0.7008959427367265
wikitext_coherence: 0.6073577000176443
wikitext_similarity_gen: 0.4154180625799478
news_perplexity: 11.844395100956126
news_rep_2: 0.07627942580959894
news_rep_3: 0.02855171328489701
news_rep_4: 0.01647334529083383
news_div_2: 0.9165035285198844
news_div_3: 0.9565710625926925
news_mauve: 0.7406578661668759
news_coherence: 0.5842249288976905
news_similarity_gen: 0.5055205831253173
el_3: 0.0708341918478911
el_5: 0.045369483855559806
el_10: 0.024793032701222444
similarity_ul: 0.4527415073297897
ma: 0.6539080953403479
piqa_: 0.6964285714285715
ai2_arc_ARC-Easy: 0.4399691358024691
ai2_arc_ARC-Challenge: 0.4399691358024691
super_glue_copa: 0.65625
winogrande_winogrande_s: 0.5521792763157894
validation_data/pubmed_qa.csv_: 0.534765625
hellaswag_: 0.3604314674179324

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 32
num_epochs: 50
lr: 0.0001
peft: lora
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 2
lr_sc: 
warmup_steps: 100
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 5e-06
su_strength: 3.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 22.534220761916544
wikitext_rep_2: 0.11118241063763208
wikitext_rep_3: 0.04568007504902546
wikitext_rep_4: 0.02543272548209092
wikitext_div_2: 0.8784739703870866
wikitext_div_3: 0.9338641587410041
wikitext_mauve: 0.6335522077005376
wikitext_coherence: 0.6053761634204439
wikitext_similarity_gen: 0.40853995447008495
news_perplexity: 13.159610499901634
news_rep_2: 0.07833044889449665
news_rep_3: 0.03105259189510832
news_rep_4: 0.018582843056355682
news_div_2: 0.9136656245399821
news_div_3: 0.9527437468022286
news_mauve: 0.7361590427163933
news_coherence: 0.5872045874120705
news_similarity_gen: 0.5025016307682161
el_3: 0.09262970760700992
el_5: 0.05457633840394696
el_10: 0.023682146580321993
similarity_ul: 0.4715016966022551
ma: 0.726
piqa_: 0.691579433497537
ai2_arc_ARC-Easy: 0.43773148148148144
ai2_arc_ARC-Challenge: 0.43773148148148144
super_glue_copa: 0.671875
winogrande_winogrande_s: 0.5459292763157895
validation_data/pubmed_qa.csv_: 0.547265625
hellaswag_: 0.35794341009309166

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 32
num_epochs: 50
lr: 0.0001
peft: lora
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 2
lr_sc: 
warmup_steps: 100
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 5e-06
su_strength: 3.0
focus: True
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: True
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 5.47945205479452
--------------------------------------------------
wikitext_perplexity: 21.44666587926949
wikitext_rep_2: 0.10401212437510907
wikitext_rep_3: 0.03908131534183515
wikitext_rep_4: 0.021252882990384882
wikitext_div_2: 0.8871506768538177
wikitext_div_3: 0.9423087944884769
wikitext_mauve: 0.7142041939594993
wikitext_coherence: 0.6051094696542699
wikitext_similarity_gen: 0.40063571368099904
news_perplexity: 12.339628637329879
news_rep_2: 0.07453117628138343
news_rep_3: 0.027119172120788345
news_rep_4: 0.015010203854250002
news_div_2: 0.9178495897433989
news_div_3: 0.957209281652048
news_mauve: 0.7499688611788307
news_coherence: 0.5816639448067107
news_similarity_gen: 0.5030919424550602
el_3: 0.06921145632224077
el_5: 0.04357172379946725
el_10: 0.023748445660731622
similarity_ul: 0.4495323127138409
ma: 0.6496134850762293
piqa_: 0.6948121921182266
ai2_arc_ARC-Easy: 0.43765432098765433
ai2_arc_ARC-Challenge: 0.43765432098765433
super_glue_copa: 0.65625
winogrande_winogrande_s: 0.5485197368421052
validation_data/pubmed_qa.csv_: 0.53671875
hellaswag_: 0.36033194512493877

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 16
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 100
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 1e-07
su_strength: 3.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 2.3498666666666668
--------------------------------------------------
wikitext_perplexity: 36.79599584195413
wikitext_rep_2: 0.09447498816754904
wikitext_rep_3: 0.032982778216054366
wikitext_rep_4: 0.016920583590712728
wikitext_div_2: 0.8944107749321014
wikitext_div_3: 0.9463316022902037
wikitext_mauve: 0.48571690101397924
wikitext_coherence: 0.5740134360051364
wikitext_similarity_gen: 0.389688130928533
news_perplexity: 18.929351515650172
news_rep_2: 0.06501560863765564
news_rep_3: 0.019915900565669543
news_rep_4: 0.009684169577753763
news_div_2: 0.9264899478294248
news_div_3: 0.9634298931933809
news_mauve: 0.6401802339942152
news_coherence: 0.5629327173726967
news_similarity_gen: 0.48566871583953397
el_3: 0.09577609339838561
el_5: 0.06135717744568
el_10: 0.0318789223448722
similarity_ul: 0.4591188778240583
ma: 0.7535166666666666
piqa_: 0.6890394088669951
ai2_arc_ARC-Easy: 0.4388888888888889
ai2_arc_ARC-Challenge: 0.4388888888888889
super_glue_copa: 0.6640625
winogrande_winogrande_s: 0.5532072368421053
validation_data/pubmed_qa.csv_: 0.547265625
hellaswag_: 0.3489864037236649

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 32
num_epochs: 50
lr: 0.0001
peft: lora
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 2
lr_sc: 
warmup_steps: 100
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 1e-06
su_strength: 10.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 9.381663113006397
--------------------------------------------------
wikitext_perplexity: 26.143279401150554
wikitext_rep_2: 0.1029343859763357
wikitext_rep_3: 0.04087529485357228
wikitext_rep_4: 0.023323569590690093
wikitext_div_2: 0.8868409130601985
wikitext_div_3: 0.9377343726710623
wikitext_mauve: 0.5844092428370068
wikitext_coherence: 0.596425131842064
wikitext_similarity_gen: 0.3986640512122956
news_perplexity: 13.292888701923811
news_rep_2: 0.07625008372898243
news_rep_3: 0.029804401588828265
news_rep_4: 0.017871655272861848
news_div_2: 0.9163019831836225
news_div_3: 0.9546316931510763
news_mauve: 0.7226103834518475
news_coherence: 0.5774911827300174
news_similarity_gen: 0.5018625301202254
el_3: 0.07383688401925342
el_5: 0.03931163710805838
el_10: 0.014784840982247392
similarity_ul: 0.42389533124719747
ma: 0.7123333333333334
piqa_: 0.7007389162561577
ai2_arc_ARC-Easy: 0.44930555555555557
ai2_arc_ARC-Challenge: 0.44930555555555557
super_glue_copa: 0.65625
winogrande_winogrande_s: 0.5412417763157895
validation_data/pubmed_qa.csv_: 0.543359375
hellaswag_: 0.35694818716315535

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 32
num_epochs: 50
lr: 0.0001
peft: lora
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 2
lr_sc: 
warmup_steps: 100
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 1e-06
su_strength: 10.0
focus: True
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: True
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 32.19178082191781
--------------------------------------------------
wikitext_perplexity: 25.281430478493874
wikitext_rep_2: 0.11044171427604091
wikitext_rep_3: 0.04491439399494052
wikitext_rep_4: 0.025525838413380315
wikitext_div_2: 0.8792066465208286
wikitext_div_3: 0.9346138475517859
wikitext_mauve: 0.5662104514576042
wikitext_coherence: 0.5925791511870687
wikitext_similarity_gen: 0.397408276997329
news_perplexity: 13.025945352350815
news_rep_2: 0.08055548597306258
news_rep_3: 0.030844404052105815
news_rep_4: 0.017851330894379534
news_div_2: 0.9118431582025963
news_div_3: 0.9532418854704676
news_mauve: 0.7095331102779613
news_coherence: 0.58156509703374
news_similarity_gen: 0.49966969623056934
el_3: 0.049669463636926516
el_5: 0.02640941846030264
el_10: 0.011964951836821608
similarity_ul: 0.417089680461485
ma: 0.6350654928065278
piqa_: 0.6985837438423645
ai2_arc_ARC-Easy: 0.4353395061728395
ai2_arc_ARC-Challenge: 0.4353395061728395
super_glue_copa: 0.65625
winogrande_winogrande_s: 0.5493009868421053
validation_data/pubmed_qa.csv_: 0.546484375
hellaswag_: 0.3542610852523273

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 32
num_epochs: 50
lr: 0.0001
peft: lora
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 2
lr_sc: 
warmup_steps: 100
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 5e-06
su_strength: 10.0
focus: True
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: True
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 5.47945205479452
--------------------------------------------------
wikitext_perplexity: 25.844881245793257
wikitext_rep_2: 0.13986951614440515
wikitext_rep_3: 0.06545488371834655
wikitext_rep_4: 0.04004346344596142
wikitext_div_2: 0.85030005601999
wikitext_div_3: 0.9150049518071643
wikitext_mauve: 0.5256206009923963
wikitext_coherence: 0.5982386494520467
wikitext_similarity_gen: 0.3886430935006369
news_perplexity: 14.789301847021514
news_rep_2: 0.09872858661257179
news_rep_3: 0.042483905067431244
news_rep_4: 0.025938988763503087
news_div_2: 0.8932523444573486
news_div_3: 0.9413934641365365
news_mauve: 0.6171146002419834
news_coherence: 0.5800692493697087
news_similarity_gen: 0.4883004922980528
el_3: 0.04883538229652112
el_5: 0.0261785696962845
el_10: 0.012161163688691055
similarity_ul: 0.4101337056160745
ma: 0.6021043590294181
piqa_: 0.6942733990147784
ai2_arc_ARC-Easy: 0.4354166666666667
ai2_arc_ARC-Challenge: 0.4354166666666667
super_glue_copa: 0.65625
winogrande_winogrande_s: 0.5469572368421052
validation_data/pubmed_qa.csv_: 0.5640625
hellaswag_: 0.34430885595296423

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 16
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 100
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 1e-08
su_strength: 3.0
focus: True
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: True
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 100
--------------------------------------------------
wikitext_perplexity: 19.658614220966214
wikitext_rep_2: 0.10025391347142626
wikitext_rep_3: 0.03869832438910012
wikitext_rep_4: 0.02230312683696476
wikitext_div_2: 0.8909845296338089
wikitext_div_3: 0.9428802936920561
wikitext_mauve: 0.670130868757167
wikitext_coherence: 0.5975616340206438
wikitext_similarity_gen: 0.40735974584891926
news_perplexity: 11.346500410995889
news_rep_2: 0.07002680314723417
news_rep_3: 0.025102197264596914
news_rep_4: 0.014377381057661039
news_div_2: 0.9229613518429142
news_div_3: 0.9604832067680306
news_mauve: 0.7659378441824607
news_coherence: 0.5761554611631599
news_similarity_gen: 0.5083968934078471
el_3: 0.11654339186320974
el_5: 0.08847623890087347
el_10: 0.06128271076047992
similarity_ul: 0.4840966152962022
ma: 0.7097917114021902
piqa_: 0.6996613300492611
ai2_arc_ARC-Easy: 0.4425154320987654
ai2_arc_ARC-Challenge: 0.4425154320987654
super_glue_copa: 0.6640625
winogrande_winogrande_s: 0.551110197368421
validation_data/pubmed_qa.csv_: 0.54453125
hellaswag_: 0.3628200024497795

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 16
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 100
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 1e-07
su_strength: 3.0
focus: True
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: True
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 8.274442538593481
--------------------------------------------------
wikitext_perplexity: 24.45286651630743
wikitext_rep_2: 0.09733903047845446
wikitext_rep_3: 0.036168203875714865
wikitext_rep_4: 0.019691981618108558
wikitext_div_2: 0.8929837824685736
wikitext_div_3: 0.9460428106406132
wikitext_mauve: 0.6089010622418245
wikitext_coherence: 0.5771465995530113
wikitext_similarity_gen: 0.3941786700738138
news_perplexity: 14.064691635125556
news_rep_2: 0.06952028512726897
news_rep_3: 0.02407345014316867
news_rep_4: 0.013473487936665543
news_div_2: 0.9232093092972842
news_div_3: 0.9607397317545076
news_mauve: 0.7011236255249726
news_coherence: 0.5707509318195966
news_similarity_gen: 0.49396541773664404
el_3: 0.06896172413487281
el_5: 0.044036593995454384
el_10: 0.024357157608538307
similarity_ul: 0.4385978811563138
ma: 0.6553575263044878
piqa_: 0.6958897783251232
ai2_arc_ARC-Easy: 0.43425925925925923
ai2_arc_ARC-Challenge: 0.43425925925925923
super_glue_copa: 0.6640625
winogrande_winogrande_s: 0.549547697368421
validation_data/pubmed_qa.csv_: 0.535546875
hellaswag_: 0.3542610852523273

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 16
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 100
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 1e-08
su_strength: 10.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 23.7168
--------------------------------------------------
wikitext_perplexity: 58.26091409464174
wikitext_rep_2: 0.07932114145100745
wikitext_rep_3: 0.025216470760718257
wikitext_rep_4: 0.011674136537605935
wikitext_div_2: 0.9066143306012229
wikitext_div_3: 0.948263306937075
wikitext_mauve: 0.4537004787199704
wikitext_coherence: 0.5749528949503019
wikitext_similarity_gen: 0.38934632964955745
news_perplexity: 24.26438376893995
news_rep_2: 0.05899401709299149
news_rep_3: 0.018497595642316733
news_rep_4: 0.009167132243744403
news_div_2: 0.9309923888716264
news_div_3: 0.9621157200433078
news_mauve: 0.6266426552920986
news_coherence: 0.5640110456611056
news_similarity_gen: 0.48627631636860547
el_3: 0.04512134513537036
el_5: 0.019018242966663695
el_10: 0.005654342815063133
similarity_ul: 0.3741772842658955
ma: 0.7025666666666667
piqa_: 0.6885006157635468
ai2_arc_ARC-Easy: 0.44344135802469137
ai2_arc_ARC-Challenge: 0.44344135802469137
super_glue_copa: 0.671875
winogrande_winogrande_s: 0.5521792763157894
validation_data/pubmed_qa.csv_: 0.547265625
hellaswag_: 0.35157398334149925

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 32
num_epochs: 50
lr: 0.0001
peft: lora
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 2
lr_sc: 
warmup_steps: 100
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 5e-06
su_strength: 10.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 1.9189765458422174
--------------------------------------------------
wikitext_perplexity: 26.978532417004768
wikitext_rep_2: 0.14017721594753893
wikitext_rep_3: 0.06687525677155347
wikitext_rep_4: 0.041517618740411696
wikitext_div_2: 0.8501770463618743
wikitext_div_3: 0.9126766057425165
wikitext_mauve: 0.48590283505019705
wikitext_coherence: 0.5926339066911073
wikitext_similarity_gen: 0.3943272386414643
news_perplexity: 16.328536463145408
news_rep_2: 0.10326838735210413
news_rep_3: 0.04789661675362332
news_rep_4: 0.031100515950541235
news_div_2: 0.8883438490332095
news_div_3: 0.9345147515414529
news_mauve: 0.6004795314794752
news_coherence: 0.5817947691655254
news_similarity_gen: 0.4852967433115668
el_3: 0.06740351379243427
el_5: 0.03272330414415767
el_10: 0.01070894302991334
similarity_ul: 0.41014289197817366
ma: 0.6444666666666666
piqa_: 0.6921182266009853
ai2_arc_ARC-Easy: 0.430787037037037
ai2_arc_ARC-Challenge: 0.430787037037037
super_glue_copa: 0.6875
winogrande_winogrande_s: 0.5401726973684211
validation_data/pubmed_qa.csv_: 0.57578125
hellaswag_: 0.3454265678588927

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 16
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 100
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 1e-07
su_strength: 10.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 2.1365333333333334
--------------------------------------------------
wikitext_perplexity: 67.3471973156083
wikitext_rep_2: 0.08002305304629663
wikitext_rep_3: 0.025785693351440035
wikitext_rep_4: 0.011002825337564198
wikitext_div_2: 0.9045930732567476
wikitext_div_3: 0.9462326593374368
wikitext_mauve: 0.4022053685815612
wikitext_coherence: 0.5683917305251137
wikitext_similarity_gen: 0.38536814069130004
news_perplexity: 25.26338245263722
news_rep_2: 0.059404747587655245
news_rep_3: 0.01850247531250233
news_rep_4: 0.009045759209538103
news_div_2: 0.9305297709515725
news_div_3: 0.9617521328861166
news_mauve: 0.5686665846302081
news_coherence: 0.5678074445382533
news_similarity_gen: 0.48986047666067206
el_3: 0.04408091848576709
el_5: 0.01821315851345713
el_10: 0.005235742204883691
similarity_ul: 0.372489495760346
ma: 0.6955
piqa_: 0.686884236453202
ai2_arc_ARC-Easy: 0.4399691358024691
ai2_arc_ARC-Challenge: 0.4399691358024691
super_glue_copa: 0.671875
winogrande_winogrande_s: 0.5474917763157895
validation_data/pubmed_qa.csv_: 0.547265625
hellaswag_: 0.34988210436060757

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 16
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 100
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 1e-07
su_strength: 10.0
focus: True
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: True
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 8.274442538593481
--------------------------------------------------
wikitext_perplexity: 30.630448985088393
wikitext_rep_2: 0.09788614512239398
wikitext_rep_3: 0.036682495558076116
wikitext_rep_4: 0.020214658548942794
wikitext_div_2: 0.8916801974403213
wikitext_div_3: 0.9440254938584963
wikitext_mauve: 0.5653189322986454
wikitext_coherence: 0.5781232003435736
wikitext_similarity_gen: 0.3923073158759526
news_perplexity: 16.15979141332428
news_rep_2: 0.06843456347221819
news_rep_3: 0.02238948986902397
news_rep_4: 0.011628392623428687
news_div_2: 0.9239633036818156
news_div_3: 0.9619941168299925
news_mauve: 0.6268897938557703
news_coherence: 0.5646835266356449
news_similarity_gen: 0.48741408842949724
el_3: 0.040684766974253606
el_5: 0.020896667020512023
el_10: 0.008982032737606546
similarity_ul: 0.39324314077204786
ma: 0.6343676186386086
piqa_: 0.6965825123152709
ai2_arc_ARC-Easy: 0.4388117283950617
ai2_arc_ARC-Challenge: 0.4388117283950617
super_glue_copa: 0.6640625
winogrande_winogrande_s: 0.5545230263157894
validation_data/pubmed_qa.csv_: 0.543359375
hellaswag_: 0.3518725502204802

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: raw_gpt
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 8
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 1
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: False
early_stop_criteria: 1.2
num_epochs_su: 2
lr_su: 0.0006
su_strength: 5
focus: False
focus_dataset: True
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 17.251436375630565
wikitext_rep_2: 0.09085207973388969
wikitext_rep_3: 0.03456424560811779
wikitext_rep_4: 0.01973051738035057
wikitext_div_2: 0.9002415397027419
wikitext_div_3: 0.9467357331545001
wikitext_mauve: 0.6417365687025358
wikitext_coherence: 0.6024357545630097
wikitext_similarity_gen: 0.4105591431255435
news_perplexity: 10.472792027393277
news_rep_2: 0.06464592645206209
news_rep_3: 0.023979502251988142
news_rep_4: 0.014247098045727009
news_div_2: 0.9282972969475723
news_div_3: 0.96132931105107
news_mauve: 0.7810487615004515
news_coherence: 0.578548963326382
news_similarity_gen: 0.5161161770468088
el_3: 0.34403423473763106
el_5: 0.30835024116955845
el_10: 0.2594707456136703
similarity_ul: 0.6620027655079262
ma: 0.9531833333333334
piqa_: 0.7028940886699508
ai2_arc_ARC-Easy: 0.46095679012345675
ai2_arc_ARC-Challenge: 0.46095679012345675
super_glue_copa: 0.65625
winogrande_winogrande_s: 0.545641447368421
validation_data/pubmed_qa.csv_: 0.53359375
hellaswag_: 0.37000857422831945

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 32
num_epochs: 50
lr: 0.0001
peft: lora
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 2
lr_sc: 
warmup_steps: 100
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 1e-05
su_strength: 3.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 1.0660980810234542
--------------------------------------------------
wikitext_perplexity: 26.07771178484228
wikitext_rep_2: 0.11311534578391749
wikitext_rep_3: 0.04718218903170686
wikitext_rep_4: 0.02687845415106001
wikitext_div_2: 0.876273381309477
wikitext_div_3: 0.9306106767310903
wikitext_mauve: 0.5912202833317418
wikitext_coherence: 0.6010637271359395
wikitext_similarity_gen: 0.4043505314966591
news_perplexity: 13.027263095867136
news_rep_2: 0.07946846200215688
news_rep_3: 0.031081756522478052
news_rep_4: 0.01844095952065465
news_div_2: 0.9128351064810755
news_div_3: 0.9533220759707057
news_mauve: 0.7350432677199479
news_coherence: 0.5830947450432644
news_similarity_gen: 0.4995937639503254
el_3: 0.09441329026194746
el_5: 0.05618141431329906
el_10: 0.024994781414571027
similarity_ul: 0.469597121987228
ma: 0.7247333333333333
piqa_: 0.6910406403940887
ai2_arc_ARC-Easy: 0.4423611111111111
ai2_arc_ARC-Challenge: 0.4423611111111111
super_glue_copa: 0.6640625
winogrande_winogrande_s: 0.5435855263157895
validation_data/pubmed_qa.csv_: 0.547265625
hellaswag_: 0.3561520088192063

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 32
num_epochs: 50
lr: 0.0001
peft: lora
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 2
lr_sc: 
warmup_steps: 100
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 1e-06
su_strength: 3.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 10.447761194029852
--------------------------------------------------
wikitext_perplexity: 22.049976659524898
wikitext_rep_2: 0.10679415266648928
wikitext_rep_3: 0.043064027719475005
wikitext_rep_4: 0.024757485531496114
wikitext_div_2: 0.8843626844345268
wikitext_div_3: 0.9383423038873159
wikitext_mauve: 0.630625745316781
wikitext_coherence: 0.5942261048511999
wikitext_similarity_gen: 0.40330862263953743
news_perplexity: 12.516016584834658
news_rep_2: 0.0775234913763603
news_rep_3: 0.030462588505273235
news_rep_4: 0.01820975381210703
news_div_2: 0.9149098633507096
news_div_3: 0.954466341635367
news_mauve: 0.755662949412174
news_coherence: 0.583941577440239
news_similarity_gen: 0.5040520217869824
el_3: 0.09133034902223347
el_5: 0.05357268728670321
el_10: 0.02290666868608726
similarity_ul: 0.46720616389834324
ma: 0.7342666666666666
piqa_: 0.6921182266009853
ai2_arc_ARC-Easy: 0.43773148148148144
ai2_arc_ARC-Challenge: 0.43773148148148144
super_glue_copa: 0.6796875
winogrande_winogrande_s: 0.5422697368421052
validation_data/pubmed_qa.csv_: 0.54921875
hellaswag_: 0.3587395884370407

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-2.7B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 32
num_epochs: 50
lr: 0.0001
peft: lora
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 2
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 1e-05
su_strength: 3.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 33.27555432212784
wikitext_rep_2: 0.11729853108448327
wikitext_rep_3: 0.0403927198072092
wikitext_rep_4: 0.019197164814735806
wikitext_div_2: 0.8717339406942656
wikitext_div_3: 0.9378077262014324
wikitext_mauve: 0.4363473882197143
wikitext_coherence: 0.5739809273177737
wikitext_similarity_gen: 0.3770369477476574
news_perplexity: 17.412230663966145
news_rep_2: 0.09107999189758427
news_rep_3: 0.032479492362490515
news_rep_4: 0.01752799488132453
news_div_2: 0.9011423700259977
news_div_3: 0.9514153044565297
news_mauve: 0.5027540926542031
news_coherence: 0.5665375606947212
news_similarity_gen: 0.474556633797233
el_3: 0.10346311850811357
el_5: 0.06544616245789436
el_10: 0.032472436672375066
similarity_ul: 0.4679117015138967
ma: 0.7297166666666667
piqa_: 0.6926242236024844
ai2_arc_ARC-Easy: 0.44229497354497355
ai2_arc_ARC-Challenge: 0.44229497354497355
super_glue_copa: 0.75
winogrande_winogrande_s: 0.5502604166666667
validation_data/pubmed_qa.csv_: 0.568359375
hellaswag_: 0.3568670382165605

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-2.7B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 32
num_epochs: 50
lr: 0.0001
peft: lora
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 2
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 5e-06
su_strength: 10.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 20.259213827108887
wikitext_rep_2: 0.09410601178118384
wikitext_rep_3: 0.03690473368138907
wikitext_rep_4: 0.021264398587397725
wikitext_div_2: 0.8964658146123031
wikitext_div_3: 0.9446647991682459
wikitext_mauve: 0.6728050218514163
wikitext_coherence: 0.5951329785278779
wikitext_similarity_gen: 0.41760168252851687
news_perplexity: 10.78666851472934
news_rep_2: 0.07077277336665759
news_rep_3: 0.029105368459896152
news_rep_4: 0.019118377846712095
news_div_2: 0.9218632616454723
news_div_3: 0.9558212381358024
news_mauve: 0.7743161615671121
news_coherence: 0.5786014876042704
news_similarity_gen: 0.515887938884636
el_3: 0.08917928987871288
el_5: 0.05197069339973803
el_10: 0.021813620782265862
similarity_ul: 0.4673149991506478
ma: 0.7681833333333333
piqa_: 0.7301242236024844
ai2_arc_ARC-Easy: 0.4852843915343915
ai2_arc_ARC-Challenge: 0.4852843915343915
super_glue_copa: 0.7410714285714286
winogrande_winogrande_s: 0.5674479166666667
validation_data/pubmed_qa.csv_: 0.56640625
hellaswag_: 0.3990644904458599

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-2.7B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: raw_gpt
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 8
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 1
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: False
early_stop_criteria: 1.2
num_epochs_su: 2
lr_su: 0.0006
su_strength: 5
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 14.09874488341278
wikitext_rep_2: 0.08522018397818945
wikitext_rep_3: 0.032994356604469026
wikitext_rep_4: 0.019720761857602086
wikitext_div_2: 0.9058395045485091
wikitext_div_3: 0.9496242124257352
wikitext_mauve: 0.7250405130525344
wikitext_coherence: 0.5995099344097985
wikitext_similarity_gen: 0.42325860052048186
news_perplexity: 9.442403577360633
news_rep_2: 0.06259805672337661
news_rep_3: 0.024125762497390655
news_rep_4: 0.014973993226042953
news_div_2: 0.9302339455774526
news_div_3: 0.9612436306204057
news_mauve: 0.8000595132460346
news_coherence: 0.5782518728795755
news_similarity_gen: 0.5264364439399034
el_3: 0.3893686969177782
el_5: 0.356024699389216
el_10: 0.3088211534187554
similarity_ul: 0.6954572305850996
ma: 0.9655666666666667
piqa_: 0.7295807453416149
ai2_arc_ARC-Easy: 0.4781746031746032
ai2_arc_ARC-Challenge: 0.4781746031746032
super_glue_copa: 0.75
winogrande_winogrande_s: 0.5635416666666667
validation_data/pubmed_qa.csv_: 0.5625
hellaswag_: 0.4076234076433121

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-2.7B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 32
num_epochs: 50
lr: 0.0001
peft: lora
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 2
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 1e-05
su_strength: 10.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 71.848057123488
wikitext_rep_2: 0.10523316727650003
wikitext_rep_3: 0.037833780861725445
wikitext_rep_4: 0.023207000543939402
wikitext_div_2: 0.8806808526727298
wikitext_div_3: 0.9354099654320353
wikitext_mauve: 0.11129263321430359
wikitext_coherence: 0.5394038603625901
wikitext_similarity_gen: 0.3535898519876218
news_perplexity: 33.674918405788056
news_rep_2: 0.07718465840551869
news_rep_3: 0.020909314571180233
news_rep_4: 0.01025127571111746
news_div_2: 0.9134243732468759
news_div_3: 0.9597260259199284
news_mauve: 0.11978993498078908
news_coherence: 0.5503976525538471
news_similarity_gen: 0.44324442550152227
el_3: 0.03872172093477371
el_5: 0.014577619216991656
el_10: 0.005209114071526187
similarity_ul: 0.3693905031672679
ma: 0.60355
piqa_: 0.6812111801242235
ai2_arc_ARC-Easy: 0.4295634920634921
ai2_arc_ARC-Challenge: 0.4295634920634921
super_glue_copa: 0.75
winogrande_winogrande_s: 0.5447916666666667
validation_data/pubmed_qa.csv_: 0.5625
hellaswag_: 0.33769904458598726

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-2.7B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 32
num_epochs: 50
lr: 0.0001
peft: lora
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 2
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 1e-06
su_strength: 3.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 16.95624429064813
wikitext_rep_2: 0.10055444942585909
wikitext_rep_3: 0.045040599841619504
wikitext_rep_4: 0.02942921384623278
wikitext_div_2: 0.891555639100582
wikitext_div_3: 0.9384132286257122
wikitext_mauve: 0.7125619558856608
wikitext_coherence: 0.6046677497279839
wikitext_similarity_gen: 0.42398000935997016
news_perplexity: 10.019018975861922
news_rep_2: 0.06986054420594705
news_rep_3: 0.02790602739827775
news_rep_4: 0.017559663658376766
news_div_2: 0.9230514538835989
news_div_3: 0.9575720663491919
news_mauve: 0.7953673108353614
news_coherence: 0.5805312684807644
news_similarity_gen: 0.5241484356064542
el_3: 0.15108120819574866
el_5: 0.10983529362323344
el_10: 0.06734421263777221
similarity_ul: 0.5252769127871221
ma: 0.8032333333333334
piqa_: 0.7290372670807453
ai2_arc_ARC-Easy: 0.48412698412698413
ai2_arc_ARC-Challenge: 0.48412698412698413
super_glue_copa: 0.7410714285714286
winogrande_winogrande_s: 0.5713541666666667
validation_data/pubmed_qa.csv_: 0.564453125
hellaswag_: 0.4036425159235669

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-2.7B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 32
num_epochs: 50
lr: 0.0001
peft: lora
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 2
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 5e-06
su_strength: 3.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 17.48403651196369
wikitext_rep_2: 0.10204997669759841
wikitext_rep_3: 0.04282223360476769
wikitext_rep_4: 0.026928885327639537
wikitext_div_2: 0.8900041995534657
wikitext_div_3: 0.9404710677423801
wikitext_mauve: 0.7402005445067672
wikitext_coherence: 0.6054368539616335
wikitext_similarity_gen: 0.4258921836950399
news_perplexity: 10.52405375607145
news_rep_2: 0.0695639481440218
news_rep_3: 0.02791424021085611
news_rep_4: 0.017745423800336096
news_div_2: 0.9234825376904757
news_div_3: 0.9575959355498552
news_mauve: 0.793967365787214
news_coherence: 0.5778676067215512
news_similarity_gen: 0.5178435903912887
el_3: 0.11551584459575716
el_5: 0.07604078049357697
el_10: 0.03927998090587588
similarity_ul: 0.497051544147466
ma: 0.7662666666666667
piqa_: 0.7263198757763975
ai2_arc_ARC-Easy: 0.4818121693121693
ai2_arc_ARC-Challenge: 0.4818121693121693
super_glue_copa: 0.7321428571428571
winogrande_winogrande_s: 0.5690104166666667
validation_data/pubmed_qa.csv_: 0.56640625
hellaswag_: 0.4008558917197452

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-2.7B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
train_batch_size: 32
num_epochs: 50
lr: 0.0001
peft: lora
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 2
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.03
num_epochs_su: 100
lr_su: 1e-06
su_strength: 10.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 18.70462327089124
wikitext_rep_2: 0.09446035092178184
wikitext_rep_3: 0.03674811703615535
wikitext_rep_4: 0.022304034683086452
wikitext_div_2: 0.8968938139136329
wikitext_div_3: 0.9451658306130831
wikitext_mauve: 0.7235134466686087
wikitext_coherence: 0.6033064053677855
wikitext_similarity_gen: 0.41902447329457837
news_perplexity: 10.592491023465094
news_rep_2: 0.06828783975747071
news_rep_3: 0.027018757902857318
news_rep_4: 0.017199591244897575
news_div_2: 0.9244955611062623
news_div_3: 0.9582068837004301
news_mauve: 0.7738304890624783
news_coherence: 0.5768210726430216
news_similarity_gen: 0.5210125190560684
el_3: 0.10586924088210095
el_5: 0.06736446037159691
el_10: 0.033133378006965745
similarity_ul: 0.4835208370962258
ma: 0.7967666666666666
piqa_: 0.7301242236024844
ai2_arc_ARC-Easy: 0.4852843915343915
ai2_arc_ARC-Challenge: 0.4852843915343915
super_glue_copa: 0.7410714285714286
winogrande_winogrande_s: 0.5690104166666667
validation_data/pubmed_qa.csv_: 0.56640625
hellaswag_: 0.4010549363057325

**************************************************
