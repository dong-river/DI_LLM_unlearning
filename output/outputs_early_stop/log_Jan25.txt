verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
num_epochs_su: 32
lr_su: 1e-06
su_strength: 3.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 41.86018515925643
wikitext_rep_2: 0.06766578670245905
wikitext_rep_3: 0.01609706820913998
wikitext_rep_4: 0.006231367776065109
wikitext_div_2: 0.9229667899683954
wikitext_div_3: 0.9644249729840363
wikitext_mauve: 0.6412491021305995
wikitext_coherence: 0.5612455245990825
wikitext_similarity_gen: 0.36325796130446336
news_perplexity: 38.04423983488293
news_rep_2: 0.04682926065356327
news_rep_3: 0.008707778229507721
news_rep_4: 0.002312137139183236
news_div_2: 0.9432714700849919
news_div_3: 0.9716831283465266
news_mauve: 0.4929723988258359
news_coherence: 0.5354263488040027
news_similarity_gen: 0.43051879512228675
el_3: 0.10239557498093897
el_5: 0.06907833188809592
el_10: 0.038595504488662495
similarity_ul: 0.4611713831301196
ma: 0.7113
piqa_: 0.6326970443349753
ai2_arc_ARC-Easy: 0.3806327160493827
ai2_arc_ARC-Challenge: 0.3806327160493827
super_glue_copa: 0.65625
winogrande_winogrande_s: 0.5331825657894738
validation_data/pubmed_qa.csv_: 0.571875
hellaswag_: 0.2980616119549241

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 1
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: False
num_epochs_su: 3
lr_su: 1e-06
su_strength: 3.0
focus: True
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: True
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 49.26244321390736
wikitext_rep_2: 0.09645376315837412
wikitext_rep_3: 0.0263314222240795
wikitext_rep_4: 0.009906502636090105
wikitext_div_2: 0.8935244079440458
wikitext_div_3: 0.9526063671860708
wikitext_mauve: 0.23672126147734385
wikitext_coherence: 0.532511482573812
wikitext_similarity_gen: 0.34135225965025623
news_perplexity: 27.96227450107361
news_rep_2: 0.0669823706307602
news_rep_3: 0.017203118169863564
news_rep_4: 0.006918489883079232
news_div_2: 0.9243324316232345
news_div_3: 0.9647344235000501
news_mauve: 0.42803427038968656
news_coherence: 0.5274135999945531
news_similarity_gen: 0.42803375042401687
el_3: 0.06397605682973793
el_5: 0.04110580247571697
el_10: 0.022479221821214156
similarity_ul: 0.43232213994426627
ma: 0.6332939660725789
piqa_: 0.6685652709359606
ai2_arc_ARC-Easy: 0.42037037037037034
ai2_arc_ARC-Challenge: 0.42037037037037034
super_glue_copa: 0.7109375
winogrande_winogrande_s: 0.5303042763157895
validation_data/pubmed_qa.csv_: 0.555078125
hellaswag_: 0.3259508206761392

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 1
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: False
num_epochs_su: 10
lr_su: 1e-06
su_strength: 10.0
focus: True
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: True
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 55.559723758157084
wikitext_rep_2: 0.0627283454416116
wikitext_rep_3: 0.011309547534331313
wikitext_rep_4: 0.0028672771282018854
wikitext_div_2: 0.9264380751851008
wikitext_div_3: 0.966271402795482
wikitext_mauve: 0.48370892367378315
wikitext_coherence: 0.531516272569989
wikitext_similarity_gen: 0.32750982360229586
news_perplexity: 37.46899374409142
news_rep_2: 0.04636100688791198
news_rep_3: 0.007461312509969249
news_rep_4: 0.0017954978540786727
news_div_2: 0.9439169112980652
news_div_3: 0.9735172233103501
news_mauve: 0.44010035434738676
news_coherence: 0.5162482394640189
news_similarity_gen: 0.4117182862638325
el_3: 0.018725018479724322
el_5: 0.005997507944299983
el_10: 0.0015370955996081841
similarity_ul: 0.3623531972194256
ma: 0.564204423448572
piqa_: 0.6551724137931034
ai2_arc_ARC-Easy: 0.41095679012345676
ai2_arc_ARC-Challenge: 0.41095679012345676
super_glue_copa: 0.7109375
winogrande_winogrande_s: 0.5232730263157894
validation_data/pubmed_qa.csv_: 0.551171875
hellaswag_: 0.3169938143067124

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: True
num_epochs_su: 100
lr_su: 1e-06
su_strength: 10.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 98.36527238775017
wikitext_rep_2: 0.049240238960421324
wikitext_rep_3: 0.006327336731053027
wikitext_rep_4: 0.0011786461796861292
wikitext_div_2: 0.9379141981962621
wikitext_div_3: 0.9673142151315575
wikitext_mauve: 0.32432244574876745
wikitext_coherence: 0.5110534131900878
wikitext_similarity_gen: 0.32031347445554686
news_perplexity: 90.06267252234916
news_rep_2: 0.03718326263348798
news_rep_3: 0.004748216310591877
news_rep_4: 0.0008136184114455572
news_div_2: 0.9484702953724801
news_div_3: 0.9682291075298667
news_mauve: 0.22071385461961499
news_coherence: 0.4971538406919198
news_similarity_gen: 0.3925352777376218
el_3: 0.011918817999472713
el_5: 0.0015212780537362397
el_10: 8.503258168833229e-05
similarity_ul: 0.3396307941351241
ma: 0.48465
piqa_: 0.6481681034482759
ai2_arc_ARC-Easy: 0.3969135802469136
ai2_arc_ARC-Challenge: 0.3969135802469136
super_glue_copa: 0.703125
winogrande_winogrande_s: 0.5230263157894737
validation_data/pubmed_qa.csv_: 0.5453125
hellaswag_: 0.30813633023027925

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 1
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: False
num_epochs_su: 3
lr_su: 1e-06
su_strength: 10.0
focus: True
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: True
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 85.59077316803673
wikitext_rep_2: 0.06485377345156909
wikitext_rep_3: 0.011346481666600702
wikitext_rep_4: 0.0027675730750359086
wikitext_div_2: 0.9219532023609823
wikitext_div_3: 0.9626693340312594
wikitext_mauve: 0.21393865400435974
wikitext_coherence: 0.501260755053129
wikitext_similarity_gen: 0.31573582968909475
news_perplexity: 49.323782801933866
news_rep_2: 0.051276153623953845
news_rep_3: 0.008539782597243719
news_rep_4: 0.0021152920380028066
news_div_2: 0.9377771224352396
news_div_3: 0.9696857609934061
news_mauve: 0.21988347874565867
news_coherence: 0.5087947161549116
news_similarity_gen: 0.4045000937948211
el_3: 0.019489734968531677
el_5: 0.006667764699251338
el_10: 0.0021095645055990955
similarity_ul: 0.3639460359894758
ma: 0.5782692720635603
piqa_: 0.6594827586206896
ai2_arc_ARC-Easy: 0.43070987654320986
ai2_arc_ARC-Challenge: 0.43070987654320986
super_glue_copa: 0.7109375
winogrande_winogrande_s: 0.5266447368421052
validation_data/pubmed_qa.csv_: 0.5421875
hellaswag_: 0.3241594194022538

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 1
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: False
num_epochs_su: 30
lr_su: 1e-06
su_strength: 3.0
focus: True
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: True
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 33.677191253697636
wikitext_rep_2: 0.08650140467348433
wikitext_rep_3: 0.02532168814196918
wikitext_rep_4: 0.010682457905392382
wikitext_div_2: 0.9046887406631557
wikitext_div_3: 0.9561960829342229
wikitext_mauve: 0.565846874927157
wikitext_coherence: 0.5636484105434442
wikitext_similarity_gen: 0.35569939224009717
news_perplexity: 23.4152250554724
news_rep_2: 0.06494452606198935
news_rep_3: 0.017374227486234305
news_rep_4: 0.007385392351846176
news_div_2: 0.9264770776346222
news_div_3: 0.9650344660779933
news_mauve: 0.5535378836195965
news_coherence: 0.5366616420061939
news_similarity_gen: 0.4374347937022488
el_3: 0.08430435228709869
el_5: 0.05781983460331973
el_10: 0.03439122407306923
similarity_ul: 0.44463979062355896
ma: 0.6397895640970582
piqa_: 0.6530172413793104
ai2_arc_ARC-Easy: 0.4050925925925926
ai2_arc_ARC-Challenge: 0.4050925925925926
super_glue_copa: 0.6875
winogrande_winogrande_s: 0.5269325657894737
validation_data/pubmed_qa.csv_: 0.569921875
hellaswag_: 0.3157000244977952

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 1
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: False
num_epochs_su: 10
lr_su: 1e-06
su_strength: 3.0
focus: True
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: True
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 44.616808066564
wikitext_rep_2: 0.07949159726001934
wikitext_rep_3: 0.020718247610370038
wikitext_rep_4: 0.0077449203853693
wikitext_div_2: 0.910069496211593
wikitext_div_3: 0.9587481087164554
wikitext_mauve: 0.4992811286837022
wikitext_coherence: 0.5492778093632371
wikitext_similarity_gen: 0.3496078607898528
news_perplexity: 24.585006504561107
news_rep_2: 0.05967090279196416
news_rep_3: 0.013975424359473246
news_rep_4: 0.005048224423944508
news_div_2: 0.9316363790657639
news_div_3: 0.9687292782677989
news_mauve: 0.5690558408209122
news_coherence: 0.5313473887652514
news_similarity_gen: 0.43243012089695987
el_3: 0.07668909376389077
el_5: 0.05154095516153272
el_10: 0.030233834176895097
similarity_ul: 0.4483870721685064
ma: 0.63732016319519
piqa_: 0.65625
ai2_arc_ARC-Easy: 0.4097993827160494
ai2_arc_ARC-Challenge: 0.4097993827160494
super_glue_copa: 0.703125
winogrande_winogrande_s: 0.5347450657894737
validation_data/pubmed_qa.csv_: 0.5609375
hellaswag_: 0.31669524742773153

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 1
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: False
num_epochs_su: 30
lr_su: 1e-06
su_strength: 10.0
focus: True
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: True
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 40.68726639756552
wikitext_rep_2: 0.06494197531998601
wikitext_rep_3: 0.012944907336148628
wikitext_rep_4: 0.0034343966099378365
wikitext_div_2: 0.9259891818027268
wikitext_div_3: 0.9681956650530653
wikitext_mauve: 0.5842979948823024
wikitext_coherence: 0.5441378757376294
wikitext_similarity_gen: 0.3503933015321539
news_perplexity: 35.24545522417433
news_rep_2: 0.049428103064866204
news_rep_3: 0.00920706902066425
news_rep_4: 0.0024890046844729874
news_div_2: 0.9408978748048538
news_div_3: 0.9713347675959491
news_mauve: 0.4264089179081398
news_coherence: 0.5207856318865164
news_similarity_gen: 0.420942141172157
el_3: 0.022508261395501362
el_5: 0.007953591556617252
el_10: 0.00247523220329536
similarity_ul: 0.36085386469927017
ma: 0.5377925703242431
piqa_: 0.6481681034482759
ai2_arc_ARC-Easy: 0.3993055555555556
ai2_arc_ARC-Challenge: 0.3993055555555556
super_glue_copa: 0.6953125
winogrande_winogrande_s: 0.5284950657894737
validation_data/pubmed_qa.csv_: 0.553125
hellaswag_: 0.3157995467907888

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: True
num_epochs_su: 100
lr_su: 1e-07
su_strength: 3.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 52.158175136294304
wikitext_rep_2: 0.06696860246174638
wikitext_rep_3: 0.013751896841318542
wikitext_rep_4: 0.0037920091658363757
wikitext_div_2: 0.9219865809609876
wikitext_div_3: 0.9646365990511491
wikitext_mauve: 0.5179705458216042
wikitext_coherence: 0.5439624283813324
wikitext_similarity_gen: 0.33996623221590855
news_perplexity: 43.57078372503313
news_rep_2: 0.04935518712697638
news_rep_3: 0.008636229094231913
news_rep_4: 0.0020661542290031035
news_div_2: 0.940093947975648
news_div_3: 0.9703855777952667
news_mauve: 0.3886489303647917
news_coherence: 0.5201734565643675
news_similarity_gen: 0.4169296897821169
el_3: 0.10755687208656976
el_5: 0.07367187273600737
el_10: 0.04186491117689357
similarity_ul: 0.468632233260603
ma: 0.74615
piqa_: 0.6460129310344828
ai2_arc_ARC-Easy: 0.40748456790123455
ai2_arc_ARC-Challenge: 0.40748456790123455
super_glue_copa: 0.6875
winogrande_winogrande_s: 0.5230263157894737
validation_data/pubmed_qa.csv_: 0.55703125
hellaswag_: 0.3115200881920627

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: True
num_epochs_su: 100
lr_su: 1e-07
su_strength: 10.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 136.56665615005522
wikitext_rep_2: 0.04707422437656598
wikitext_rep_3: 0.0058838667079099535
wikitext_rep_4: 0.0009418907958703296
wikitext_div_2: 0.9358428566971552
wikitext_div_3: 0.9617338377183421
wikitext_mauve: 0.11472013663781981
wikitext_coherence: 0.49101688093044227
wikitext_similarity_gen: 0.31178837006624177
news_perplexity: 87.75211797359981
news_rep_2: 0.04066879818687505
news_rep_3: 0.004938924086636051
news_rep_4: 0.0008175940922190808
news_div_2: 0.9454793408558856
news_div_3: 0.96826478765364
news_mauve: 0.10051653362865198
news_coherence: 0.4924780553080646
news_similarity_gen: 0.3874387510623634
el_3: 0.01451416538852958
el_5: 0.002148526893235098
el_10: 0.00012077776966021971
similarity_ul: 0.3405782135713031
ma: 0.5831666666666667
piqa_: 0.6514008620689655
ai2_arc_ARC-Easy: 0.40625
ai2_arc_ARC-Challenge: 0.40625
super_glue_copa: 0.7109375
winogrande_winogrande_s: 0.5279605263157895
validation_data/pubmed_qa.csv_: 0.540234375
hellaswag_: 0.3129134002939735

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: False
early_stop_criteria: 1.2
num_epochs_su: 3
lr_su: 1e-06
su_strength: 3.0
focus: True
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: True
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 46.39044128042338
wikitext_rep_2: 0.10043032386809857
wikitext_rep_3: 0.03401632633023937
wikitext_rep_4: 0.016186306832572165
wikitext_div_2: 0.8878656805614463
wikitext_div_3: 0.9440277332482693
wikitext_mauve: 0.3631630247573414
wikitext_coherence: 0.5610242434397545
wikitext_similarity_gen: 0.36924157177601735
news_perplexity: 21.163112953095887
news_rep_2: 0.07523159101085831
news_rep_3: 0.023659738797773642
news_rep_4: 0.011405963491544829
news_div_2: 0.9165729799218247
news_div_3: 0.9597137577771931
news_mauve: 0.48123480587466394
news_coherence: 0.5497398832404756
news_similarity_gen: 0.46135211128308307
el_3: 0.05423873178213702
el_5: 0.03235408837261049
el_10: 0.01655424007179178
similarity_ul: 0.4169719261293265
ma: 0.6312540261971226
piqa_: 0.6863454433497537
ai2_arc_ARC-Easy: 0.43773148148148144
ai2_arc_ARC-Challenge: 0.43773148148148144
super_glue_copa: 0.7265625
winogrande_winogrande_s: 0.5362664473684211
validation_data/pubmed_qa.csv_: 0.5453125
hellaswag_: 0.342218887800098

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: False
early_stop_criteria: 1.2
num_epochs_su: 10
lr_su: 1e-06
su_strength: 3.0
focus: True
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: True
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 48.91416191597752
wikitext_rep_2: 0.09566748524919737
wikitext_rep_3: 0.0265497101357495
wikitext_rep_4: 0.00967999525198987
wikitext_div_2: 0.8944018644608578
wikitext_div_3: 0.9526110968549979
wikitext_mauve: 0.2598583068397974
wikitext_coherence: 0.5363024396908328
wikitext_similarity_gen: 0.3372165385734201
news_perplexity: 29.066437654202726
news_rep_2: 0.06437576198274424
news_rep_3: 0.015902687382219127
news_rep_4: 0.005984039978514927
news_div_2: 0.9266400826780885
news_div_3: 0.9659419679805427
news_mauve: 0.41235472767796444
news_coherence: 0.5315469080708416
news_similarity_gen: 0.43068027605958453
el_3: 0.06481377254928364
el_5: 0.04166620595375614
el_10: 0.0230508813109652
similarity_ul: 0.4311705569997813
ma: 0.6329181876744685
piqa_: 0.6696428571428572
ai2_arc_ARC-Easy: 0.4179783950617284
ai2_arc_ARC-Challenge: 0.4179783950617284
super_glue_copa: 0.7109375
winogrande_winogrande_s: 0.5331825657894738
validation_data/pubmed_qa.csv_: 0.551171875
hellaswag_: 0.32525416462518375

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: False
early_stop_criteria: 1.2
num_epochs_su: 30
lr_su: 1e-06
su_strength: 3.0
focus: True
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: True
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 39.2238162575254
wikitext_rep_2: 0.08306270345886997
wikitext_rep_3: 0.020458271714205323
wikitext_rep_4: 0.0070777309644518465
wikitext_div_2: 0.9076752937996041
wikitext_div_3: 0.9600900296088403
wikitext_mauve: 0.5611922230619654
wikitext_coherence: 0.557491785908583
wikitext_similarity_gen: 0.35387342366409796
news_perplexity: 24.766263466448905
news_rep_2: 0.06028339096046724
news_rep_3: 0.014137513883033507
news_rep_4: 0.005030509694233567
news_div_2: 0.9315270703025766
news_div_3: 0.9693237800962393
news_mauve: 0.5649890985544747
news_coherence: 0.5329011711941297
news_similarity_gen: 0.43456284949473434
el_3: 0.0786728176164474
el_5: 0.053490591535956145
el_10: 0.03181869483102092
similarity_ul: 0.4498211752156808
ma: 0.6369443847970797
piqa_: 0.6557112068965517
ai2_arc_ARC-Easy: 0.408641975308642
ai2_arc_ARC-Challenge: 0.408641975308642
super_glue_copa: 0.7109375
winogrande_winogrande_s: 0.5370888157894738
validation_data/pubmed_qa.csv_: 0.56484375
hellaswag_: 0.31669524742773153

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.2
num_epochs_su: 100
lr_su: 1e-06
su_strength: 3.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 0.4266666666666667
--------------------------------------------------
wikitext_perplexity: 61.20067159700291
wikitext_rep_2: 0.08975941607330684
wikitext_rep_3: 0.023306042091277904
wikitext_rep_4: 0.008245253888902212
wikitext_div_2: 0.8987190287534375
wikitext_div_3: 0.9526548813361811
wikitext_mauve: 0.25989902027062517
wikitext_coherence: 0.5280804987085359
wikitext_similarity_gen: 0.34130005281385845
news_perplexity: 32.058157280877076
news_rep_2: 0.06384673908706041
news_rep_3: 0.014809852091304074
news_rep_4: 0.005184460494360803
news_div_2: 0.9265166636610237
news_div_3: 0.9659608732970193
news_mauve: 0.3226895082533915
news_coherence: 0.5310606937484438
news_similarity_gen: 0.43978306805516454
el_3: 0.10548178415363432
el_5: 0.07139552799006169
el_10: 0.04080797362908671
similarity_ul: 0.4661793041108875
ma: 0.7443166666666666
piqa_: 0.6734144088669951
ai2_arc_ARC-Easy: 0.4295524691358025
ai2_arc_ARC-Challenge: 0.4295524691358025
super_glue_copa: 0.7109375
winogrande_winogrande_s: 0.527672697368421
validation_data/pubmed_qa.csv_: 0.551171875
hellaswag_: 0.3290589784419402

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: False
early_stop_criteria: 1.2
num_epochs_su: 3
lr_su: 1e-06
su_strength: 10.0
focus: True
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: True
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 83.88512822791449
wikitext_rep_2: 0.08333260943973335
wikitext_rep_3: 0.02306797149079956
wikitext_rep_4: 0.009053097344687275
wikitext_div_2: 0.9034085943845589
wikitext_div_3: 0.9506561921479878
wikitext_mauve: 0.11475676651474981
wikitext_coherence: 0.5233428840206438
wikitext_similarity_gen: 0.3377893329942728
news_perplexity: 37.72145699708981
news_rep_2: 0.06900374700140162
news_rep_3: 0.018355124952398227
news_rep_4: 0.007780149441221815
news_div_2: 0.9210593809276295
news_div_3: 0.9620125010052688
news_mauve: 0.17264674043156047
news_coherence: 0.52426986390376
news_similarity_gen: 0.4305516286585916
el_3: 0.024353996141587963
el_5: 0.010292416987145163
el_10: 0.004087021866194518
similarity_ul: 0.35896923513243595
ma: 0.5881468756710329
piqa_: 0.6836514778325123
ai2_arc_ARC-Easy: 0.43070987654320986
ai2_arc_ARC-Challenge: 0.43070987654320986
super_glue_copa: 0.7109375
winogrande_winogrande_s: 0.5383634868421052
validation_data/pubmed_qa.csv_: 0.558984375
hellaswag_: 0.33761789563939243

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: True
early_stop_criteria: 1.2
num_epochs_su: 100
lr_su: 1e-07
su_strength: 3.0
focus: False
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: False
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
early_stop_epoch: 3.6314666666666664
--------------------------------------------------
wikitext_perplexity: 62.80953065486408
wikitext_rep_2: 0.09268931714037401
wikitext_rep_3: 0.026198433463206782
wikitext_rep_4: 0.010606127757746239
wikitext_div_2: 0.895367164442196
wikitext_div_3: 0.9488903880929118
wikitext_mauve: 0.2685947158678973
wikitext_coherence: 0.547405515740178
wikitext_similarity_gen: 0.35664532688379735
news_perplexity: 28.248328855885195
news_rep_2: 0.06572296042338972
news_rep_3: 0.01663167595035277
news_rep_4: 0.00627963727505564
news_div_2: 0.9247774083768315
news_div_3: 0.964650381536239
news_mauve: 0.3850924663492755
news_coherence: 0.5420417329704619
news_similarity_gen: 0.45347942138648223
el_3: 0.10496707446857337
el_5: 0.07096621946567302
el_10: 0.040607234770798965
similarity_ul: 0.46424979959479534
ma: 0.7458666666666667
piqa_: 0.67503078817734
ai2_arc_ARC-Easy: 0.4364969135802469
ai2_arc_ARC-Challenge: 0.4364969135802469
super_glue_copa: 0.71875
winogrande_winogrande_s: 0.5362664473684211
validation_data/pubmed_qa.csv_: 0.555078125
hellaswag_: 0.3341575820676139

**************************************************
verbose: False
filtered_extract_challenge_data_path: ./data/extract_challenge/filtered.npy
model_name_or_path: EleutherAI/gpt-neo-1.3B
teacher_model: EleutherAI/gpt-neo-125m
cache_dir: /nlp/data/riverd/unlearn
method: soft_unlikelihood
contrastive_coef: 0.1
strat: relu2
relu_threshold: 0
weight_subtraction_coef: 0.25
num_epochs: 50
lr: 0.0001
peft: ft
rank: 8
lora_alpha: 16
train_num: 15000
gradient_accu: 4
lr_sc: 
warmup_steps: 0
weight_decay: 0.0
dropout: 0.0
early_stop: False
early_stop_criteria: 1.2
num_epochs_su: 10
lr_su: 1e-06
su_strength: 10.0
focus: True
focus_dataset: False
focus_coeff: 10
focus_type: entity
focus_hard: True
do_sample: True
top_k: 50
cd_num_token: 1000
DP: False
DP_coef: 0
--------------------------------------------------
wikitext_perplexity: 93.30500256629439
wikitext_rep_2: 0.0627558446584628
wikitext_rep_3: 0.011770431012603123
wikitext_rep_4: 0.0026975509313534934
wikitext_div_2: 0.9242253584989781
wikitext_div_3: 0.9613888144786645
wikitext_mauve: 0.16946138539377648
wikitext_coherence: 0.5048617526907544
wikitext_similarity_gen: 0.3151098558739987
news_perplexity: 47.45009245877052
news_rep_2: 0.049940417907259026
news_rep_3: 0.00849383477483514
news_rep_4: 0.0020620991116271302
news_div_2: 0.9397179311964193
news_div_3: 0.9707159273787781
news_mauve: 0.2538820902498491
news_coherence: 0.5116713322491285
news_similarity_gen: 0.4061415824398864
el_3: 0.01842155530464747
el_5: 0.00591406195446902
el_10: 0.0015054274445295238
similarity_ul: 0.3647358157276871
ma: 0.5776250805239425
piqa_: 0.6600215517241379
ai2_arc_ARC-Easy: 0.4294753086419753
ai2_arc_ARC-Challenge: 0.4294753086419753
super_glue_copa: 0.7265625
winogrande_winogrande_s: 0.5258634868421053
validation_data/pubmed_qa.csv_: 0.547265625
hellaswag_: 0.3238608525232729

**************************************************
